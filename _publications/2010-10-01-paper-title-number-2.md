---
title: "Spatio-Temporal Action Detection with a Motion Sense and Semantic Correction Framework"
collection: publications
permalink: /publication/2010-10-01-paper-title-number-2
excerpt: 'The paper proposes a new framework called Motion Sense and Semantic Correction (MS-SC) to address the challenges of distinguishing between action and non-action features and the fusion of information across different modalities in spatio-temporal action detection. The Motion Sense Module (MSM) increases the distance between action and non-action features, improving feature discriminability. The Semantic Correction Fusion Module (SFM) facilitates interaction between features from different modalities, maximizing information integration.'
date: 2024-3-18
venue: '2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'
slidesurl: 'http://academicpages.github.io/files/slides2.pdf'
paperurl: 'https://ieeexplore.ieee.org/document/10447413'
citation: 'Zhang Y, Yu C, Fu C, et al. Spatio-Temporal Action Detection with a Motion Sense and Semantic Correction Framework[C]//ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2024: 3645-3649.'
---

Accurately distinguishing between action-related features and nonaction-related features is crucial in spatio-temporal action detection tasks. Additionally, the calibration and fusion of information across different modalities remain challenging. This paper proposes a novel Motion Sense and Semantic Correction framework (MS-SC) to address these issues. The MS-SC framework achieves accurate detection by fusing features from images (spatial dimension) and videos (spatio-temporal dimension). A Motion Sense Module (MSM) is proposed to significantly increase the feature distance between action and non-action features in the semantic space, enhancing feature discriminability. Considering the complementary nature of information across different modalities, an efficient Semantic Correction Fusion Module (SFM) is introduced to facilitate interaction between features of distinct modalities and maximize their complementary information integration. To evaluate the performance of the MSSC framework, extensive experiments were conducted on two challenging datasets, UCF101-24 and AVA. The results demonstrate the effectiveness of the MS-SC framework in handling spatio-temporal action detection tasks.
